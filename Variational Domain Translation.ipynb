{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Domain Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.poutine\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import warnings\n",
    "# warnings.simplefilter(\"always\", UserWarning)\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "cont_run = ''\n",
    "# cont_run = './logs/run1'\n",
    "\n",
    "if not cont_run:\n",
    "    logdir = pathlib.Path('./logs')\n",
    "    i = 1\n",
    "    while (logdir/f'run{i}').exists():\n",
    "        i += 1\n",
    "    logdir = logdir/f'run{i}'\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "else:\n",
    "    logdir = pathlib.Path(cont_run)\n",
    "    assert logdir.exists(), f'specified logdir \"{cont_run}\" does not exist!'\n",
    "\n",
    "writer = SummaryWriter(logdir)\n",
    "print(f'Logging to: {logdir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "hparams_file = ''\n",
    "# hparams_file = './hparams.yaml'\n",
    "\n",
    "if hparams_file:\n",
    "    with open(hparams_file) as f:\n",
    "        hparams = yaml.safe_load(f)\n",
    "else:\n",
    "    hparams = {\n",
    "        'image_size': [3, 32, 32],\n",
    "        'batch_size': 64,\n",
    "        'num_epochs': 1000,\n",
    "        'val_every': 1,\n",
    "        # optim hparams\n",
    "        'lr': 2.0e-4,\n",
    "        'betas': [0.5, 0.999],\n",
    "        'clip_grad': 1.0,\n",
    "        # model hparams\n",
    "        'cls': 1.0,\n",
    "        'ent_reg': 1.0e-5,\n",
    "    }\n",
    "\n",
    "writer.add_hparams(\n",
    "    {k: v for k, v in hparams.items() if not isinstance(v, list)},\n",
    "    {}\n",
    ")\n",
    "writer.add_text('hparams', yaml.dump(hparams, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mnist2usps import MNIST2USPS\n",
    "\n",
    "input_shape = hparams['image_size']\n",
    "batch_size = hparams['batch_size']\n",
    "val_split = 0.2\n",
    "\n",
    "dataset = MNIST2USPS(image_size=input_shape[1:], batch_size=batch_size, val_split=val_split)\n",
    "s_train_loader, s_val_loader, s_test_loader = dataset.get_loaders('src')\n",
    "t_train_loader, t_val_loader, t_test_loader = dataset.get_loaders('tgt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "num_samples = 50\n",
    "\n",
    "samples = next(iter(s_train_loader))\n",
    "xs, ys = samples[0][:num_samples], samples[1][:num_samples]\n",
    "\n",
    "print(xs.shape, ys.shape)\n",
    "grid_img = torchvision.utils.make_grid(xs, nrow=10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "samples = next(iter(t_train_loader))\n",
    "xt, yt = samples[0][:num_samples], samples[1][:num_samples]\n",
    "\n",
    "print(xt.shape, yt.shape)\n",
    "grid_img = torchvision.utils.make_grid(xt, nrow=10)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.network import VDTNet\n",
    "model = VDTNet(hparams=hparams).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "print(summary(model, input_size=(batch_size, *input_shape), depth=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.distrib.utils import *\n",
    "\n",
    "class Visualizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        writer,\n",
    "        device,\n",
    "        batch_size=64,\n",
    "        image_keys=('x_A', 'x_B', 'x1_A', 'x1_B', 'x_AB', 'x_BA'),\n",
    "        embed_keys=(('z_A', 'z_B', 'z_AB', 'z_BA'), ('h_A', 'h_B'))\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.writer = writer\n",
    "\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.image_keys = image_keys\n",
    "        self.embed_keys = embed_keys\n",
    "    \n",
    "    def vis_samples(self, samples, step, tag, labels=None, mode='both'):\n",
    "        outputs_all = {}\n",
    "\n",
    "        training = self.model.training\n",
    "        self.model.eval()\n",
    "\n",
    "        # collect outputs\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(samples), self.batch_size):\n",
    "                if mode == 'src' or mode == 'tgt':\n",
    "                    x = torch.stack(samples[i:i+self.batch_size]).to(self.device)\n",
    "                    if labels is not None:\n",
    "                        y = torch.stack(labels[i:i+self.batch_size]).to(self.device)\n",
    "                    else:\n",
    "                        y = None\n",
    "                    outputs = self.model(x, y, d=mode)\n",
    "                \n",
    "                elif mode == 'both':\n",
    "                    x_A = torch.stack(samples[0][i:i+self.batch_size]).to(self.device)\n",
    "                    x_B = torch.stack(samples[1][i:i+self.batch_size]).to(self.device)\n",
    "                    if labels is not None:\n",
    "                        y_A = torch.stack(labels[0][i:i+self.batch_size]).to(self.device)\n",
    "                        y_B = torch.stack(labels[1][i:i+self.batch_size]).to(self.device)\n",
    "                    else:\n",
    "                        y_A = None\n",
    "                        y_B = None\n",
    "                    outputs = self.model(x_A, y_A, d='src')\n",
    "                    outputs.update(self.model(x_B, y_B, d='tgt'))\n",
    "                \n",
    "                else:\n",
    "                    raise ValueError(f'invalid mode={mode}')\n",
    "                \n",
    "                for k, v in outputs.items():\n",
    "                    if v is None:\n",
    "                        continue\n",
    "                    if k not in outputs_all:\n",
    "                        outputs_all[k] = []\n",
    "                    outputs_all[k] += [v]\n",
    "        \n",
    "        self.model.train(training)\n",
    "        \n",
    "        # concatenate output tensors\n",
    "        for k, v in outputs_all.items():\n",
    "            outputs_all[k] = torch.cat(v, dim=0)\n",
    "        \n",
    "        # visualize images\n",
    "        for k in self.image_keys:\n",
    "            if k in outputs_all:\n",
    "                writer.add_images(f'{tag}/{k}', outputs_all[k], step)\n",
    "        \n",
    "        # visualize embeddings\n",
    "        for group in self.embed_keys:\n",
    "            g_embed_mat = []\n",
    "            g_metadata = []\n",
    "            g_label_img = []\n",
    "            g_tags = []\n",
    "\n",
    "            for k in group:\n",
    "                if k in outputs_all:\n",
    "                    embed = outputs_all[k].flatten(1)\n",
    "                    g_embed_mat += [embed]\n",
    "                    g_metadata += [k] * embed.shape[0]\n",
    "                    g_tags += [k]\n",
    "                    if k.endswith('AB'):\n",
    "                        g_label_img += [outputs_all['x_AB']]\n",
    "                    elif k.endswith('BA'):\n",
    "                        g_label_img += [outputs_all['x_BA']]\n",
    "                    elif k.endswith('A'):\n",
    "                        g_label_img += [outputs_all['x_A']]\n",
    "                    elif k.endswith('B'):\n",
    "                        g_label_img += [outputs_all['x_B']]\n",
    "                    else:\n",
    "                        g_label_img += [torch.zeros(embed.shape[0], *input_shape)]\n",
    "            \n",
    "            g_embed_mat = torch.cat(g_embed_mat, dim=0)\n",
    "            g_label_img = torch.cat(g_label_img, dim=0)\n",
    "\n",
    "            writer.add_embedding(\n",
    "                g_embed_mat,\n",
    "                metadata=g_metadata,\n",
    "                label_img=g_label_img,\n",
    "                global_step=step,\n",
    "                tag=f'{tag}/{\",\".join(g_tags)}'\n",
    "            )\n",
    "    \n",
    "    def vis_priors(self, step, tag, dims=(0, 1)):\n",
    "        dims = list(dims)\n",
    "\n",
    "        mu_zA, mu_zB = self.model.prior_z.mu.numpy(force=True)\n",
    "        cov_zA, cov_zB = self.model.prior_z.get_cov().numpy(force=True)\n",
    "\n",
    "        mu_h = self.model.prior_h.mu.numpy(force=True)[0]\n",
    "        cov_h = self.model.prior_h.get_cov().numpy(force=True)[0]\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        plot_2d_gaussian(mu_zA[dims], cov_zA[dims, :][:, dims], label='prior_zA')\n",
    "        plot_2d_gaussian(mu_zB[dims], cov_zB[dims, :][:, dims], label='prior_zB')\n",
    "        plot_2d_gaussian(mu_h[dims], cov_h[dims, :][:, dims], label='prior_h')\n",
    "        writer.add_figure(tag, fig, step)\n",
    "        fig.clear()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = Visualizer(model, writer, device, batch_size=batch_size)\n",
    "n_vis = 50\n",
    "\n",
    "vxs_train = [s_train_loader.dataset[i][0] for i in range(n_vis)]\n",
    "vxt_train = [t_train_loader.dataset[i][0] for i in range(n_vis)]\n",
    "\n",
    "vxs_val = [s_val_loader.dataset[i][0] for i in range(n_vis)]\n",
    "vxt_val = [t_val_loader.dataset[i][0] for i in range(n_vis)]\n",
    "\n",
    "vxs_test = [s_test_loader.dataset[i][0] for i in range(n_vis)]\n",
    "vxt_test = [t_test_loader.dataset[i][0] for i in range(n_vis)]\n",
    "\n",
    "visualizer.vis_samples((vxs_train, vxt_train), 0, 'train', mode='both')\n",
    "visualizer.vis_samples((vxs_val, vxt_val), 0, 'val', mode='both')\n",
    "visualizer.vis_priors(0, 'priors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader_s, loader_t):\n",
    "    elbo_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "\n",
    "    loss_dict = {}\n",
    "    len_loader = min(len(loader_s), len(loader_t))\n",
    "\n",
    "    training = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (xs, ys), (xt, yt) in zip(loader_s, loader_t):\n",
    "            if xs.shape[0] != xt.shape[0]:\n",
    "                continue\n",
    "            N = xs.shape[0]\n",
    "            xs, ys = xs.to(device), ys.to(device)\n",
    "            xt, yt = xt.to(device), yt.to(device)\n",
    "\n",
    "            # evaluate ELBO loss\n",
    "            data_s = (xs, ys, 'src')\n",
    "            data_t = (xt, yt, 'tgt')\n",
    "\n",
    "            elbo_s = elbo_fn(model.model, model.guide, *data_s)\n",
    "            elbo_t = elbo_fn(model.model, model.guide, *data_t)\n",
    "            loss = elbo_s + elbo_t\n",
    "\n",
    "            # evaluate classifier accuracy\n",
    "            model_trace = pyro.poutine.trace(model.model_cls).get_trace(xs)\n",
    "            ys_pred = model_trace.nodes['cls/y']['fn'].probs\n",
    "\n",
    "            model_trace = pyro.poutine.trace(model.model_cls).get_trace(xt)\n",
    "            yt_pred = model_trace.nodes['cls/y']['fn'].probs\n",
    "\n",
    "            acc_s = (ys_pred.argmax(-1) == ys).sum()\n",
    "            acc_t = (yt_pred.argmax(-1) == yt).sum()\n",
    "\n",
    "            loss_dict1 = {\n",
    "                'loss': loss,\n",
    "                'elbo_s': elbo_s,\n",
    "                'elbo_t': elbo_t,\n",
    "                'acc_s': acc_s,\n",
    "                'acc_t': acc_t\n",
    "            }\n",
    "            for k in loss_dict1:\n",
    "                if k not in loss_dict:\n",
    "                    loss_dict[k] = 0\n",
    "                loss_dict[k] = loss_dict[k] + loss_dict1[k]\n",
    "    \n",
    "    model.train(training)\n",
    "\n",
    "    for k in loss_dict:\n",
    "        loss_dict[k] = loss_dict[k] / (len_loader*batch_size)\n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cont_run:\n",
    "    model.load_state_dict(torch.load(logdir/'last_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.distrib.dist_fn import *\n",
    "\n",
    "# ELBO loss functions\n",
    "elbo_fn_s = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "elbo_fn_t = pyro.infer.TraceEnum_ELBO(max_plate_nesting=1).differentiable_loss\n",
    "\n",
    "# setup guide for enumeration\n",
    "model.enum_guide = pyro.infer.config_enumerate(model.guide, 'sequential', expand=True)\n",
    "\n",
    "entropy_fn = EntropyFullGaussian()\n",
    "\n",
    "# setup optimizer\n",
    "num_epochs = hparams['num_epochs']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['lr'], betas=hparams['betas'])\n",
    "\n",
    "validate_every = hparams['val_every']\n",
    "\n",
    "model.set_hparams(hparams)\n",
    "model.train()\n",
    "step = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "len_loader = min(len(s_train_loader), len(t_train_loader))\n",
    "\n",
    "print(f'len(s_train_loader): {len(s_train_loader)}')\n",
    "print(f'len(t_train_loader): {len(t_train_loader)}')\n",
    "print(f'len_loader: {len_loader}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):\n",
    "    # for (xs, ys), (xt, yt) in tqdm(\n",
    "    #     zip(s_train_loader, t_train_loader), total=len_loader, leave=False\n",
    "    # ):\n",
    "    for (xs, ys), (xt, yt) in zip(s_train_loader, t_train_loader):\n",
    "        if xs.shape[0] != xt.shape[0]:\n",
    "            continue\n",
    "        N = xs.shape[0]\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "        xt, yt = xt.to(device), yt.to(device)\n",
    "\n",
    "        if int(step % (hparams['prior_update']*2) / hparams['prior_update']) == 0:\n",
    "            model.grad_mode('network')\n",
    "        else:\n",
    "            model.grad_mode('priors')\n",
    "\n",
    "        data_s = (xs, ys, 'src')\n",
    "        data_t = (xt, None, 'tgt')\n",
    "\n",
    "        # supervised ELBO loss\n",
    "        elbo_s = elbo_fn_s(model.model, model.guide, *data_s)\n",
    "        elbo_s /= N\n",
    "        # # unsupervised ELBO loss\n",
    "        elbo_t = elbo_fn_t(model.model, model.enum_guide, *data_t)\n",
    "        elbo_t /= N\n",
    "        # classifier loss\n",
    "        # l_cls = elbo_fn_s(model.model_cls, model.guide_cls, xs, ys)\n",
    "        # l_cls /= N\n",
    "        # total loss\n",
    "        loss = (\n",
    "            elbo_s +\n",
    "            elbo_t\n",
    "            # hparams['cls'] * l_cls\n",
    "        )\n",
    "\n",
    "        # additional forward pass\n",
    "        outputs = {}\n",
    "        outputs.update(model(*data_s))\n",
    "        outputs.update(model(*data_t))\n",
    "\n",
    "        # entropy regularization\n",
    "        z_all = torch.cat([outputs['z_A'], outputs['z_B']], dim=0)\n",
    "        ent_z = entropy_fn(z_all.mean(0), torch.cov(z_all.T))\n",
    "        # loss += hparams['ent_reg'] * -ent_z\n",
    "\n",
    "        h_all = torch.cat([outputs['h_A'], outputs['h_B']], dim=0)\n",
    "        ent_h = entropy_fn(h_all.mean(0), torch.cov(h_all.T))\n",
    "        # loss += hparams['ent_reg'] * -ent_h\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        if hparams['clip_grad'] > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), hparams['clip_grad'])\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_dict = {\n",
    "            'loss': loss,\n",
    "            'elbo_s': elbo_s,\n",
    "            'elbo_t': elbo_t,\n",
    "            # 'l_cls': l_cls,\n",
    "            'ent_z': ent_z,\n",
    "            'ent_h': ent_h\n",
    "        }\n",
    "\n",
    "        step += 1\n",
    "        for k, v in loss_dict.items():\n",
    "            writer.add_scalar(f'train/{k}', v.item(), step)\n",
    "        \n",
    "        # train statistics\n",
    "        train_loss_dict = evaluate(model, [(xs, ys)], [(xt, yt)])\n",
    "        for k, v in train_loss_dict.items():\n",
    "            writer.add_scalar(f'train-eval/{k}', v.item(), step)\n",
    "    \n",
    "    if epoch % validate_every == 0:\n",
    "        val_loss_dict = evaluate(model, s_val_loader, t_val_loader)\n",
    "        for k, v in val_loss_dict.items():\n",
    "            writer.add_scalar(f'val/{k}', v.item(), step)\n",
    "        \n",
    "        # visualize\n",
    "        visualizer.vis_samples((vxs_train, vxt_train), step, 'train', mode='both')\n",
    "        visualizer.vis_samples((vxs_val, vxt_val), step, 'val', mode='both')\n",
    "        visualizer.vis_priors(step, 'priors')\n",
    "\n",
    "        if val_loss_dict['loss'] < best_val_loss:\n",
    "            best_val_loss = val_loss_dict['loss']\n",
    "            torch.save(model.state_dict(), logdir/'best_model.pth')\n",
    "\n",
    "        torch.save(model.state_dict(), logdir/'last_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(logdir/'last_model.pth'))\n",
    "loss_dict = evaluate(model, s_test_loader, t_test_loader)\n",
    "from pprint import pprint\n",
    "pprint(loss_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test set visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(logdir/'last_model.pth'))\n",
    "visualizer.vis_samples((vxs_test, vxt_test), step, 'test', mode='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
